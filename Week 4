The first sentence of Ohm’s piece hit me like a brick, as it went to the greatest concern I have about the big data wave, one which may even outweigh the benefits of the open government data which has washed ashore. Government data, even more so than private data, raises threat of easy and comprehensive personal data dispersal in the hands of those who manage to reidentify it. The threat of blackmail rings powerfully in a world where strangers on Twitter reveal each other’s home addresses for harassment, and this is especially true as the government often knows our most expensive secrets.

Reidentification recasts anonymized data sets as redacted documents. It would seem that the kinds of documents which get redacted, generally get kept secret in the first place, and redaction is only a method to protect as much as possible when revealing the document is legally required. Is redaction the highest standard we want open government data held to? Is the risk that Ohm shows us comes with the free flow of anonymized data worth the rewards we’ve discussed, from accountable government to service delivery? This question can’t be weighed unless those risks are clearly discussed.

The MA story is surprising and funny, and highlights how even a state government can hold such a wealth of useful, verified, and easy to access data which can so easily be used to learn secrets. If this data was around in 1997, and reveals so much, how much more problematic does open government data become today? Moreover, just as government data has increased, for good reasons, the healthcare sector has increased its appetite for data collection and shared use disproportionately. The HIPAA story indicates that even with the better intentions and more resources than MA, Congress and HHS struggle to address the challenge of protecting health information from reidentification.

The recent data theft at Anthem brought home a problem even further upstream than questionable anonymization and the mosaic theory: when data is anonymized, it must have first existed in an identifiable way. Existing anonymized data alerts potential thieves and hackers to the existence of a complete data collection, which they can then steal and mine from.

 

The mosaic theory has arisen as a necessity in a world in which it seems like everyone, and government especially, will do whatever it takes to pull as much actionable data from each person as possible.  I liked Kerr’s aside in that one might normally want to clearly label and highlight a new theory in order to persuade a court on the merits, but the party here instead looked to sneak it into jurisprudence.

 

Reading Riley, I’m almost unsure that police looking through a physical phone is a data issue. I’m reminded of the Zoolander scene in which Ben Stiller tries to get files out of a computer by breaking it open. In many ways, it’s best to think of data physically in order to protect it best using the Fourth Amendment, which has been developed to protect analog information, but which has only recently begun adapting to the digital age. It’s easy for the court to say that data about an individual accessed directly through his or her phone is protected like physical evidence, but that just points the police and future courts towards the many other ways to access data. While the court could have addressed this issue in that way, it instead incorporated concerns about the mosaic theory, and the dangers to privacy that collected data sets pose, into the ruling. In thinking about the physical location of the data on servers, the court flips my original thinking on its head and sees the cell phone as separate from its access to so many otherwise private records.

 

 
